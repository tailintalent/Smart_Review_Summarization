{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, ASCENDING\n",
    "from srs.database import connect_to_db\n",
    "from srs.utilities import Sentence, tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import math\n",
    "import word2vec\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import gzip\n",
    "import ast\n",
    "# Loading Word2Vec model\n",
    "current_directory = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "model_path = os.path.join(current_directory[:-6], 'srs/predictor_data/text8.bin')\n",
    "model = word2vec.load(model_path)\n",
    "def sort_list(list, sort_index, reverse = True):\n",
    "    list_sorted = sorted(list, key=lambda tup: tup[sort_index], reverse = reverse)\n",
    "    return list_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the prod_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield ast.literal_eval(l)\n",
    "\n",
    "\n",
    "def construct_prod_dict(meta_file_path_list):\n",
    "    \"\"\"return a dictionary for product metadata\"\"\"\n",
    "    prod_dict = {}\n",
    "    for meta_file_path in meta_file_path_list:\n",
    "        metaParser = parse(meta_file_path)\n",
    "        client, db = connect_to_db()\n",
    "        i = 0       \n",
    "        print \"Building the product dictionary for %s\" % meta_file_path\n",
    "        for meta in metaParser:\n",
    "            i+=1\n",
    "            if i % 100000 == 0:\n",
    "                print i\n",
    "            product_id = meta['asin']\n",
    "            category = meta['categories'][0]\n",
    "            product_name = \"\"\n",
    "            brand = \"\"\n",
    "            if 'title' in meta:\n",
    "                inter = meta['title'].split()\n",
    "                if len (inter) > 1:\n",
    "                    product_name_short = inter[0] + ' ' + inter[1]\n",
    "                else:\n",
    "                    product_name_short = inter[0]\n",
    "            if 'brand' in meta:\n",
    "                brand = meta['brand']\n",
    "            prod_dict[product_id]={'category': category, 'product_name': product_name_short, 'brand': brand}\n",
    "        print i\n",
    "    return prod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the product dictionary for ../../Datasets/Full_Reviews/meta_Electronics.json.gz\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "498196\n",
      "Building the product dictionary for ../../Datasets/Full_Reviews/meta_Cell_Phones_and_Accessories.json.gz\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "346793\n"
     ]
    }
   ],
   "source": [
    "Electronics_Meta_Path = '../../Datasets/Full_Reviews/meta_Electronics.json.gz'\n",
    "Phone_Meta_Path = '../../Datasets/Full_Reviews/meta_Cell_Phones_and_Accessories.json.gz'\n",
    "\n",
    "prod_dict = construct_prod_dict([Electronics_Meta_Path,Phone_Meta_Path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions accumulate all the sentences by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category_dict(prod_dict):\n",
    "    \"\"\"Build a dictionary whose key is the category tuple, and the value is a list of product_ids:\"\"\"\n",
    "    client, db = connect_to_db()\n",
    "    cursor = db.product_collection.find()\n",
    "    category_dict = {}\n",
    "    i = 0\n",
    "    for product in cursor:\n",
    "        i += 1   \n",
    "        if i % 100000 == 0:\n",
    "            print i\n",
    "        category = product['category']\n",
    "        category_short = tuple(category[:4]) #generally category is 4-tuple. Now limit to the first three tuple\n",
    "        product_id = product['product_id']\n",
    "        product_name = \"\"\n",
    "        brand = \"\"\n",
    "        if product_id in prod_dict:\n",
    "            product_info = prod_dict[product_id]\n",
    "            if 'product_name' in product_info:\n",
    "                product_name = product_info['product_name']\n",
    "            if 'brand' in product_info:\n",
    "                brand = product_info['brand']\n",
    "\n",
    "        if category_short not in category_dict:\n",
    "            category_dict[category_short] = {\"product_id\": [product_id], \"brand_list\": [], \"product_name_list\": []}\n",
    "        else:\n",
    "            category_dict[category_short]['product_id'].append(product_id)\n",
    "            \n",
    "        if len(product_name) > 0:\n",
    "            category_dict[category_short]['product_name_list'].append(product_name)\n",
    "        if len(brand) > 0:\n",
    "            if brand not in category_dict[category_short]['brand_list']:\n",
    "                category_dict[category_short]['brand_list'].append(brand)\n",
    "            \n",
    "    client.close()\n",
    "    print i\n",
    "  \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def sort_category_dict(category_dict, isPrint = False):\n",
    "    \"\"\"Sort the categories according to the number of products in that category, and print them from top\"\"\"\n",
    "    category_list_sorted = []\n",
    "    category_list = []\n",
    "\n",
    "    for key in category_dict:\n",
    "        length = len(category_dict[key]['product_id'])\n",
    "        category_list.append([key,length,key[:3],0])\n",
    "    category_list_sorted = sorted(category_list, key=lambda tup: (tup[2],tup[1]), reverse=True)\n",
    "    \n",
    "    category_list_sorted_dict = {}\n",
    "    for Id in range(len(category_list_sorted)):\n",
    "        category_list_sorted[Id][3]=Id\n",
    "        category = category_list_sorted[Id][0]\n",
    "        category_dict[category][\"category_id\"] = Id\n",
    "        category_list_sorted_dict[Id] = category_list_sorted[Id][:3]\n",
    "    \n",
    "    if isPrint:\n",
    "        for Id in range(len(category_list_sorted)):\n",
    "            print Id, category_list_sorted_dict[Id][:2]\n",
    "        \n",
    "    return category_list_sorted_dict\n",
    "\n",
    "\n",
    "def combine_category_custom(category_dict_raw, category_list_sorted_dict):\n",
    "    category_dict = copy.deepcopy(category_dict_raw)\n",
    "    print \"Number of categories in original set: %g\"%len(category_dict_raw)\n",
    "    print \"Combined category ID:\"\n",
    "    f = open('Aspect_and_wordlist_txt/combined_dict.txt','r')\n",
    "    for line in f:\n",
    "        combine_info = eval(line)\n",
    "        print combine_info\n",
    "        if len(combine_info) > 0:\n",
    "            Id_to_combine = combine_info[0]\n",
    "            name_info = combine_info[1]\n",
    "            category_name_combined = category_list_sorted_dict[name_info[0]][0][:name_info[1]]\n",
    "            category_id = category_dict_raw[category_list_sorted_dict[name_info[0]][0]][\"category_id\"]\n",
    "            new_prod_id_list = []\n",
    "            new_product_name_list = []\n",
    "            new_brand_list = []\n",
    "            for Id in Id_to_combine:\n",
    "                category_name = category_list_sorted_dict[Id][0]\n",
    "                new_prod_id_list += category_dict[category_name][\"product_id\"]\n",
    "                new_product_name_list += category_dict[category_name][\"product_name_list\"]\n",
    "                new_brand_list += category_dict[category_name][\"brand_list\"]\n",
    "                category_dict.pop(category_name, 0)\n",
    "            category_dict[category_name_combined] = {\"category_id\": category_id,\"product_id\": new_prod_id_list,\\\n",
    "                        \"product_name_list\": new_product_name_list, \"brand_list\": new_brand_list}\n",
    "    f.close()\n",
    "    print \"Number of categories in the new dict: %g\"%len(category_dict)\n",
    "      \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def combine_small_category(category_dict_raw, category_list_sorted, prod_num_threshold = 100, shrink_level = 3):\n",
    "    category_dict = copy.deepcopy(category_dict_raw)\n",
    "    i = 0\n",
    "    for i in range(len(category_list_sorted)):\n",
    "        i += 1\n",
    "        category_name = category_list_sorted[-i][1]\n",
    "        prod_num = category_list_sorted[-i][0]\n",
    "        if prod_num > prod_num_threshold:\n",
    "            break\n",
    "        if len(category_name) > shrink_level:\n",
    "            category_name_shrink = category_name[:shrink_level]\n",
    "            if category_name_shrink in category_dict:\n",
    "                category_dict[category_name_shrink] += category_dict[category_name]\n",
    "                category_dict.pop(category_name,0)\n",
    "                print \"{0} combined into {1}\".format(category_name_shrink, category_name)\n",
    "            else:\n",
    "                print \"{0} not combined\".format(category_name_shrink)\n",
    "        else:\n",
    "            print \"{0} length not enough.\".format(category_name)\n",
    "    \n",
    "    return category_dict\n",
    "\n",
    "\n",
    "def save_category_dict_to_db(category_dict, dropPrevious = False):\n",
    "    client, db = connect_to_db()\n",
    "    db_category_data = db.category_data\n",
    "    if dropPrevious == True:\n",
    "        db_category_data.delete_many({})\n",
    "    for category in category_dict:\n",
    "        query = {\"category_id\": category_dict[category][\"category_id\"]}\n",
    "        update_field = {\"category\": list(category),\\\n",
    "                        \"prod_id_list\": category_dict[category][\"product_id\"], \\\n",
    "                        \"brand_list\":  category_dict[category][\"brand_list\"],\\\n",
    "                        \"product_name_list\": category_dict[category][\"product_name_list\"]}\n",
    "        db_category_data.update_one(query, {\"$set\": update_field}, True)\n",
    "        \n",
    "    client.close()\n",
    "\n",
    "\n",
    "def show_category_dict_info(category_dict, min_prod_num = 1000):\n",
    "    new_list = []\n",
    "    for category in category_dict:\n",
    "        new_list.append([len(category_dict[category][\"product_id\"]),category,category_dict[category][\"category_id\"]])\n",
    "    \n",
    "    new_list = sorted(new_list, key=lambda tup: tup[0], reverse=True)\n",
    "    \n",
    "    for item in new_list:\n",
    "        if int(item[0]) < min_prod_num:        \n",
    "            break\n",
    "        print \"{0},{1},{2}\".format(item[0],item[1],item[2])\n",
    "\n",
    "\n",
    "def get_sentence_from_category(category_list):\n",
    "    \"\"\"Obtain all the review sentences from a list of category tuple:\"\"\"\n",
    "    if isinstance(category_list, dict):\n",
    "        category_lists = [category_list]\n",
    "    else:\n",
    "        category_lists = category_list\n",
    "    \n",
    "    category_content_list = []\n",
    "    \n",
    "    for category in category_lists:\n",
    "        print \"{0}:\".format(category)\n",
    "        client, db = connect_to_db()\n",
    "        product_id_list = category_dict[category][\"product_id\"]\n",
    "        category_contents = {\"category\": category,\"sentence_list\": [], \"brand_list\": category_dict[category][\"brand_list\"],\\\n",
    "                            \"product_name_list\": category_dict[category][\"product_name_list\"]}\n",
    "        review_num = 0\n",
    "        for product_id in product_id_list:\n",
    "            query_res = list(db.product_collection.find({\"product_id\": product_id}))\n",
    "            contents = query_res[0][\"contents\"]\n",
    "            category_contents['sentence_list'] += contents\n",
    "            review_num += len(query_res[0][\"review_ids\"])\n",
    "        print \"  ({0}, {1}, {2})\".format(len(product_id_list), review_num, len(category_contents['sentence_list']))      \n",
    "        category_content_list.append(category_contents)\n",
    "        \n",
    "    client.close()\n",
    "\n",
    "    return category_content_list\n",
    "\n",
    "\n",
    "def get_sentence_from_category_ensemble(category_dict, max_prod_chosen = 500, min_product_level = 500):\n",
    "    client, db = connect_to_db()\n",
    "    full_sentence_list = []\n",
    "    print \"Getting product categories: (num_sentence_chosen, category):\"\n",
    "    for category in category_dict:\n",
    "        if len(category_dict[category]) < min_product_level:\n",
    "            continue\n",
    "        product_id_list = category_dict[category][\"product_id\"]\n",
    "        random.shuffle(product_id_list)\n",
    "        new_sentence = []\n",
    "        for product_id in product_id_list[:max_prod_chosen]:\n",
    "            query_res = list(db.product_collection.find({\"product_id\": product_id}))\n",
    "            contents = query_res[0][\"contents\"]\n",
    "            new_sentence += contents\n",
    "        print len(new_sentence),category\n",
    "        full_sentence_list += new_sentence\n",
    "    client.close()\n",
    "    print \"Number of sentences: {0}\".format(len(full_sentence_list))\n",
    "    \n",
    "    all_category_content = {\"sentence_list\": full_sentence_list}\n",
    "    return all_category_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "793315\n"
     ]
    }
   ],
   "source": [
    "category_dict_raw = get_category_dict(prod_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in original set: 512\n",
      "Combined category ID:\n",
      "[[16, 17], [17, 2]]\n",
      "[[20, 21, 22, 23, 26, 28, 29, 30, 31, 32], [22, 3]]\n",
      "[[38, 39, 40, 41, 42], [38, 3]]\n",
      "[[105, 106], [105, 3]]\n",
      "[[108, 109, 110, 111, 112], [112, 3]]\n",
      "[[139, 140, 141], [139, 3]]\n",
      "[[176, 177, 178, 179, 180, 181, 182, 183, 184], [176, 3]]\n",
      "[[277, 278, 279, 280], [277, 3]]\n",
      "[[282, 283, 284, 285, 286, 287, 288], [282, 3]]\n",
      "[[297, 298, 299, 300, 301], [297, 3]]\n",
      "[[302, 303, 304], [302, 3]]\n",
      "[[308, 309, 310, 311, 312, 313, 314], [308, 3]]\n",
      "[[316, 321], [316, 3]]\n",
      "[[322, 323, 324, 325, 326, 327, 328, 329, 330, 331], [322, 3]]\n",
      "[[356, 357, 358, 359, 360], [356, 3]]\n",
      "[[362, 363, 364, 365, 366], [366, 3]]\n",
      "[[367, 368, 369, 370], [367, 3]]\n",
      "[[371, 372, 373, 374, 375, 376, 377], [371, 3]]\n",
      "[[379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393], [379, 3]]\n",
      "[[399, 400], [399, 3]]\n",
      "[[417, 418, 419, 420, 421], [417, 3]]\n",
      "[[427, 428, 429, 430], [427, 2]]\n",
      "[[433, 434, 435, 436, 437, 438], [433, 2]]\n",
      "[[439, 440, 441, 442, 443, 444, 445], [439, 3]]\n",
      "[[462, 463, 464], [462, 3]]\n",
      "[[469, 470, 471], [469, 3]]\n",
      "Number of categories in the new dict: 396\n"
     ]
    }
   ],
   "source": [
    "category_list_sorted_dict = sort_category_dict(category_dict_raw, isPrint = False)\n",
    "category_dict = combine_category_custom(category_dict_raw, category_list_sorted_dict)\n",
    "save_category_dict_to_db(category_dict, dropPrevious = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207742,(u'Cell Phones & Accessories', u'Cases', u'Waterproof Cases'),439\n",
      "25256,(u'Cell Phones & Accessories', u'Accessories', u'Accessory Kits'),474\n",
      "25245,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Cases & Sleeves'),129\n",
      "21726,(u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories', u'MP3 Player Accessories'),78\n",
      "16275,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Batteries'),155\n",
      "15453,(u'Electronics', u'Camera & Photo', u'Accessories', u'Batteries & Chargers'),332\n",
      "15195,(u'Cell Phones & Accessories', u'Accessories', u'Screen Protectors'),450\n",
      "15051,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Chargers & Adapters'),156\n",
      "13548,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Bags & Cases'),157\n",
      "13115,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Cables & Interconnects'),401\n",
      "11747,(u'Electronics', u'Camera & Photo', u'Bags & Cases'),322\n",
      "11524,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Cables & Interconnects'),203\n",
      "10638,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Headphones'),402\n",
      "9544,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Audio'),253\n",
      "9150,(u'Electronics', u'Computers & Accessories', u'Laptops'),154\n",
      "8855,(u'Cell Phones & Accessories', u'Accessories', u'Batteries'),469\n",
      "7915,(u'Electronics', u'Camera & Photo', u'Digital Cameras'),308\n",
      "7416,(u'Cell Phones & Accessories', u'Cell Phones'),433\n",
      "7408,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Car Chargers'),459\n",
      "6912,(u'Electronics', u'Computers & Accessories', u'Data Storage'),176\n",
      "6645,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Memory'),185\n",
      "6620,(u'Electronics', u'Camera & Photo', u'Accessories', u'Digital Camera Accessories'),333\n",
      "6595,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Travel Chargers'),460\n",
      "6351,(u'Cell Phones & Accessories', u'Accessories', u'Replacement Parts'),452\n",
      "5953,(u'Cell Phones & Accessories', u'Accessories', u'Data Cables'),457\n",
      "5771,(u'Electronics', u'Accessories & Supplies', u'Batteries, Chargers & Accessories', u'AC Adapters'),394\n",
      "5090,(u'Electronics', u'Television & Video', u'Televisions'),22\n",
      "5057,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Memory Cards'),204\n",
      "4981,(u'Electronics', u'Camera & Photo', u'Accessories', u'Lens Accessories'),334\n",
      "4947,(u'Electronics', u'Home Audio', u'Stereo Components', u'Speakers'),90\n",
      "4928,(u'Electronics', u'Computers & Accessories', u'Data Storage', u'USB Flash Drives'),175\n",
      "4804,(u'Cell Phones & Accessories', u'Accessories', u'Headsets', u'Wired Headsets'),454\n",
      "4781,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboards'),205\n",
      "4770,(u'Cell Phones & Accessories', u'Accessories', u'Headsets', u'Bluetooth Headsets'),455\n",
      "4576,(u'Cell Phones & Accessories', u'Accessories', u'Car Accessories', u'Car Cradles & Mounts'),465\n",
      "4485,(u'Electronics', u'Computers & Accessories'),228\n",
      "4362,(u'Electronics', u'Camera & Photo', u'Lighting & Studio', u'Photo Studio'),292\n",
      "4348,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Video Projector Accessories'),206\n",
      "4124,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories', u'Audio & Video Accessories'),230\n",
      "4004,(u'Electronics', u'Camera & Photo', u'Accessories', u'Filters & Accessories'),335\n",
      "3980,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Screen Protectors'),130\n",
      "3878,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Mice'),207\n",
      "3870,(u'Electronics', u'Computers & Accessories', u'Desktops'),174\n",
      "3829,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'TV Accessories & Parts'),403\n",
      "3821,(u'Electronics', u'Camera & Photo', u'Lighting & Studio', u'Lighting'),293\n",
      "3783,(u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories', u'MP3 Players'),79\n",
      "3737,(u'Electronics', u'Camera & Photo', u'Lenses'),297\n",
      "3731,(u'Electronics', u'Computers & Accessories', u'Monitors'),153\n",
      "3729,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Connectors & Adapters'),404\n",
      "3694,(u'Electronics', u'Camera & Photo', u'Tripods & Monopods'),282\n",
      "3686,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Replacement Screens'),158\n",
      "3517,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Fans & Cooling'),186\n",
      "3512,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Graphics Cards'),187\n",
      "3346,(u'Electronics', u'eBook Readers & Accessories', u'Covers'),15\n",
      "3346,(u'Cell Phones & Accessories', u'Accessories', u'Stylus Pens'),447\n",
      "3215,(u'Electronics', u'Camera & Photo', u'Video Surveillance', u'Surveillance Cameras'),266\n",
      "3176,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Computer Cable Adapters'),208\n",
      "3155,(u'Electronics', u'Computers & Accessories', u'Laptop & Netbook Computer Accessories', u'Skins & Decals'),159\n",
      "3078,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Remote Controls'),405\n",
      "3037,(u'Electronics', u'Computers & Accessories', u'PDAs, Handhelds & Accessories'),139\n",
      "3020,(u'Electronics', u'Television & Video', u'DVD Players & Recorders'),38\n",
      "2970,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Network Adapters'),142\n",
      "2944,(u'Cell Phones & Accessories', u'Accessories', u'Phone Charms'),453\n",
      "2833,(u'Electronics', u'Accessories & Supplies', u'Telephone Accessories', u'Batteries'),353\n",
      "2804,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories'),231\n",
      "2625,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Motherboards'),188\n",
      "2452,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Safety & Security'),254\n",
      "2439,(u'Electronics', u'Computers & Accessories', u'Tablets'),136\n",
      "2379,(u'Electronics', u'Camera & Photo', u'Video', u'Camcorders'),271\n",
      "2353,(u'Electronics', u'Car & Vehicle Electronics', u'Car Electronics', u'Car Video'),255\n",
      "2343,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Headphone Accessories'),406\n",
      "2340,(u'Electronics', u'Accessories & Supplies', u'Blank Media'),379\n",
      "2298,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Bundles'),131\n",
      "2281,(u'Electronics', u'GPS & Navigation', u'GPS System Accessories', u'Vehicle Mounts'),114\n",
      "2190,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Hard Drive Enclosures'),209\n",
      "2187,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Media Storage & Organization'),407\n",
      "2096,(u'Electronics', u'Camera & Photo', u'Binoculars & Scopes'),316\n",
      "1955,(u'Electronics', u'Home Audio', u'Stereo Components', u'Receivers & Amplifiers'),91\n",
      "1929,(u'Electronics', u'Camera & Photo', u'Accessories', u'Flash Accessories'),336\n",
      "1854,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Computer Speakers'),210\n",
      "1840,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboard & Mice Accessories'),211\n",
      "1824,(u'Electronics', u'Portable Audio & Video', u'CB & Two-Way Radios', u'Accessories'),83\n",
      "1813,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Distribution'),408\n",
      "1804,(u'Cell Phones & Accessories', u'Accessories', u'Chargers', u'Cell Phone Docks'),461\n",
      "1710,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Power Supplies'),189\n",
      "1701,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Headsets & Microphones'),212\n",
      "1698,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Computer Cases'),190\n",
      "1665,(u'Electronics', u'Accessories & Supplies'),423\n",
      "1579,(u'Electronics', u'Car & Vehicle Electronics', u'Vehicle Electronics Accessories', u'Vehicle Audio & Video Installation'),232\n",
      "1559,(u'Electronics', u'Computers & Accessories', u'Routers'),138\n",
      "1543,(u'Electronics', u'Camera & Photo'),352\n",
      "1513,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Memory Card Readers'),213\n",
      "1486,(u'Electronics', u'Computers & Accessories', u'Video Projectors'),128\n",
      "1460,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Chargers & Adapters'),132\n",
      "1459,(u'Electronics', u'Accessories & Supplies', u'Cord Management'),371\n",
      "1436,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Skins & Decals'),133\n",
      "1409,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Input Devices'),214\n",
      "1374,(u'Electronics', u'Computers & Accessories', u'Computer Components'),191\n",
      "1370,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories'),134\n",
      "1361,(u'Electronics', u'Camera & Photo', u'Accessories', u'Professional Video Accessories'),337\n",
      "1347,(u'Cell Phones & Accessories', u'Accessories'),475\n",
      "1302,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Monitor Accessories'),215\n",
      "1263,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Uninterrupted Power Supply (UPS)'),216\n",
      "1238,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Hubs'),143\n",
      "1211,(u'Electronics', u'Security & Surveillance', u'Home Security Systems'),58\n",
      "1204,(u'Electronics', u'Camera & Photo', u'Flashes'),302\n",
      "1162,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Keyboard & Mouse Combos'),217\n",
      "1151,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'I/O Port Cards'),192\n",
      "1134,(u'Electronics', u'Computers & Accessories', u'Webcams'),124\n",
      "1126,(u'Electronics', u'GPS & Navigation', u'Sports & Handheld GPS'),112\n",
      "1124,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'Internal Optical Drives'),193\n",
      "1105,(u'Electronics', u'Camera & Photo', u'Film Photography', u'Film Cameras'),305\n",
      "1088,(u'Electronics', u'eBook Readers & Accessories', u'Skins'),10\n",
      "1081,(u'Electronics', u'Computers & Accessories', u'Cables & Accessories', u'Surge Protectors'),218\n",
      "1066,(u'Electronics', u'Computers & Accessories', u'Computer Components', u'CPU Processors'),194\n",
      "1034,(u'Electronics', u'Accessories & Supplies', u'Audio & Video Accessories', u'Antennas'),409\n",
      "1030,(u'Electronics', u'Computers & Accessories', u'Networking Products', u'Switches'),144\n",
      "1022,(u'Electronics', u'Camera & Photo', u'Accessories', u'Tripod & Monopod Accessories'),338\n",
      "1012,(u'Electronics', u'Computers & Accessories', u'Touch Screen Tablet Accessories', u'Stands'),135\n",
      "1004,(u'Electronics', u'Camera & Photo', u'Underwater Photography'),277\n"
     ]
    }
   ],
   "source": [
    "show_category_dict_info(category_dict, min_prod_num = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_category_content = get_sentence_from_category_ensemble(category_dict, max_prod_chosen = 1000, min_product_level = 0)\n",
    "# get_tf_idf(all_category_content, is_idf_db = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect extraction: the following functions collects sentences from one category, obtain each word's tf-idf score, and choose aspect candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category_word_scores(category_id_list):\n",
    "    \"\"\"Get tf-idf score for each word\n",
    "       The dictionary records for each word as a key, the [num_word, num_doc] value, where num_word means the number of \n",
    "       that word in the sentence_list, and num_doc means the number of sentences this word appears in.\n",
    "    \"\"\"\n",
    "    \n",
    "    client, db = connect_to_db()\n",
    "    db_word_score_list = db.word_score_list\n",
    "    db_product_collection = db.product_collection\n",
    "    db_category_data = db.category_data\n",
    "    # Collecting each word's data for that category\n",
    "    for category_id in category_id_list:\n",
    "        query_category = list(db_category_data.find({\"category_id\": category_id}))\n",
    "        if len(query_category) == 0:\n",
    "            print \"{0} not in db, skip.\".format(category_id)\n",
    "            continue\n",
    "        category_content = query_category[0]\n",
    "        category = category_content[\"category\"]\n",
    "        prod_id_list = category_content[\"prod_id_list\"]\n",
    "        prod_num = len(prod_id_list)\n",
    "        if prod_num < 10:\n",
    "            continue\n",
    "        \n",
    "        word_statistics = {}\n",
    "        \n",
    "        i = 0\n",
    "        for product_id in prod_id_list:          \n",
    "            query_res = list(db_product_collection.find({\"product_id\": product_id}))\n",
    "            contents = query_res[0][\"contents\"]\n",
    "            for sentence in contents:\n",
    "                i += 1\n",
    "                if i % 50000 == 0:\n",
    "                    print i\n",
    "                tokens = tokenize(sentence, stem = False)\n",
    "                tokens_count = Counter(tokens)\n",
    "                for word in tokens_count:        \n",
    "                    if word not in word_statistics:\n",
    "                        word_statistics[word] = [tokens_count[word], 1]\n",
    "                    else:\n",
    "                        word_statistics[word][0] += tokens_count[word]\n",
    "                        word_statistics[word][1] += 1\n",
    "        \n",
    "        total_num_doc = i\n",
    "        print \"Id: {0}, num_prod: {1}, num_sentence: {2}\".format(category_id, prod_num, total_num_doc)\n",
    "        print \"{0}\".format(category)\n",
    "        word_scores = []\n",
    "        \n",
    "        max_word_freq = 0\n",
    "        for word in word_statistics:\n",
    "            if word_statistics[word][0] > max_word_freq:\n",
    "                max_word_freq = word_statistics[word][0]\n",
    "        \n",
    "        # Calculating tf-idf for the category\n",
    "        for word in word_statistics:               \n",
    "            word_rawdata = word_statistics[word]\n",
    "            word_freq = word_rawdata[0]\n",
    "            num_doc = word_rawdata[1]\n",
    "            tf = float(word_freq) / max_word_freq \n",
    "                                   \n",
    "            idf_category = math.log(float(total_num_doc)/(num_doc))\n",
    "            query_idf = list(db_word_score_list.find({\"word\": word}))\n",
    "            if len(query_idf) > 0:\n",
    "                idf = query_idf[0][\"full_word_score\"][2]\n",
    "            else:\n",
    "                idf = idf_category\n",
    "            word_scores.append([word, tf * idf, tf, idf_category, idf, word_freq, num_doc])\n",
    "                                   \n",
    "        word_statistics.clear()\n",
    "        word_scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        # Obtaining brand_list words and product_name words:\n",
    "        brand_list = category_content[\"brand_list\"]\n",
    "        product_name_list = category_content[\"product_name_list\"]\n",
    "        brand_word_list = []\n",
    "        product_name_word_list =[]\n",
    "        for brand in brand_list:     \n",
    "            brand_word = brand.split()[0]\n",
    "            if brand_word not in brand_word_list:\n",
    "                brand_word_list.append(brand_word)\n",
    "        for product_name in product_name_list:   \n",
    "            product_name_word = product_name.split()[0]\n",
    "            if product_name_word not in product_name_word_list:\n",
    "                product_name_word_list.append(product_name_word)       \n",
    "        \n",
    "        # Update database:\n",
    "        query = {\"category_id\": category_id}\n",
    "        update_field = {\"word_scores\": word_scores, \"brand_word_list\": brand_word_list,\\\n",
    "                        \"product_name_word_list\": product_name_word_list}\n",
    "        db_category_data.update_one(query, {\"$set\": update_field}, True)\n",
    "        \n",
    "        # Get aspect_cadidate:\n",
    "        if prod_num < 20:\n",
    "            num_candidate = 60\n",
    "        else:\n",
    "            num_candidate = 50\n",
    "        get_aspect_cadidate([category_id], num_candidate, [\"NN\"], db_category_data, db_word_score_list)\n",
    "  \n",
    "    client.close()                          \n",
    "    \n",
    "\n",
    "def get_excluded_words():\n",
    "    f = open(\"Aspect_and_wordlist_txt/excluded_words.txt\",'r')\n",
    "    excluded_words = eval(f.read())\n",
    "    return excluded_words\n",
    "\n",
    "\n",
    "def get_aspect_cadidate(category_id_list, num_candidate = 30, tag_list = [\"NN\"], db_category_data = None, db_word_score_list = None):\n",
    "    '''Get cadidate aspects from word_tf_idf. Only words whose tag belong to tag_list and score > threshold will pass'''  \n",
    "    # check if db cursor is given:\n",
    "    external_db = True\n",
    "    if (not db_category_data) or (not db_word_score_list):\n",
    "        external_db = False\n",
    "        client, db = connect_to_db()\n",
    "        if not db_category_data:\n",
    "            db_category_data = db.category_data\n",
    "        if not db_word_score_list:\n",
    "            db_word_score_list = db.word_score_list\n",
    "\n",
    "    for category_id in category_id_list: \n",
    "        full_word_freq_thresh = 30\n",
    "        full_num_doc_thresh = 10\n",
    "        \n",
    "        query_category = list(db_category_data.find({\"category_id\": category_id}))\n",
    "        if len(query_category) == 0:\n",
    "            print \"{0} not in db, skip.\".format(category_id)\n",
    "            continue\n",
    "        category_content = query_category[0]\n",
    "        category = category_content[\"category\"]\n",
    "        if external_db == False:\n",
    "            print category \n",
    "        if \"word_scores\" not in category_content:\n",
    "            print \"{0} don't have word_scores, skip.\".format(category_id)\n",
    "            continue\n",
    "        word_scores = category_content[\"word_scores\"]\n",
    "        brand_word_list = category_content[\"brand_word_list\"]\n",
    "        product_name_word_list = category_content[\"product_name_word_list\"]\n",
    "        num_prod = len(category_content[\"prod_id_list\"])\n",
    "        if num_prod < 50:\n",
    "            full_word_freq_thresh = int(num_prod/ 4)\n",
    "            full_num_doc_thresh = int(num_prod / 8)\n",
    "                    \n",
    "        aspect_candidate = []\n",
    "        j = 0\n",
    "        excluded_words = get_excluded_words()\n",
    "        for word_data in word_scores:\n",
    "            word = word_data[0]\n",
    "            # Various criterior to exclude the word:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            if word_data[5] <= 1:\n",
    "                continue\n",
    "            if word in excluded_words:\n",
    "                continue\n",
    "            query_idf = list(db_word_score_list.find({\"word\": word}))\n",
    "            if len(query_idf) > 0:\n",
    "                full_word_score = query_idf[0][\"full_word_score\"]\n",
    "                full_word_freq = full_word_score[4]\n",
    "                full_num_doc = full_word_score[5]\n",
    "                if full_word_freq < full_word_freq_thresh or full_num_doc < full_num_doc_thresh:\n",
    "                    continue            \n",
    "            if word in brand_word_list:\n",
    "                if full_word_freq < 100:\n",
    "                    continue\n",
    "            if word in product_name_word_list:\n",
    "                if full_word_freq < 200:\n",
    "                    continue                        \n",
    "                                  \n",
    "            word_tag = pos_tag([word])[0][1]\n",
    "            # If the tag is in tag_list:\n",
    "            if word_tag in tag_list:\n",
    "                j += 1\n",
    "                aspect_candidate.append(word_data)\n",
    "                print \"%s     \\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f\\t%g\\t%g\"%(word, word_data[1],word_data[2],word_data[3],word_data[4],\\\n",
    "                                                               word_data[5], word_data[6])\n",
    "            if j > num_candidate:\n",
    "                break\n",
    "               \n",
    "        # Update database:\n",
    "        query = {\"category_id\": category_id}\n",
    "        update_field = {\"aspect_candidate\": aspect_candidate}\n",
    "        db_category_data.update_one(query, {\"$set\": update_field}, True)      \n",
    "        print\n",
    "    if external_db == False:\n",
    "        client.close()\n",
    "\n",
    "\n",
    "\n",
    "def save_word_score_to_db(category_content_list, isRewrite = False):\n",
    "    client, db = connect_to_db()\n",
    "    db_word_score_list = db.word_score_list\n",
    "    if isRewrite == True:\n",
    "        db_word_score_list.delete_many({})\n",
    "        db_word_score_list.create_index([(\"word\", ASCENDING)])\n",
    "        db_word_score_list.create_index([(\"category\", ASCENDING)])\n",
    "    \n",
    "    if isinstance(category_content_list, dict):\n",
    "        category_content_lists = [category_content_list]\n",
    "    else:\n",
    "        category_content_lists = category_content_list\n",
    "    \n",
    "    for category_content in category_content_lists:\n",
    "        word_tf_idf = category_content[\"word_tf_idf\"]\n",
    "        category = category_content[\"category\"]\n",
    "        i = 0\n",
    "        for word_data in word_tf_idf:\n",
    "            i += 1\n",
    "            if i % 50000 == 0:\n",
    "                print i\n",
    "            word = word_data[0]\n",
    "            word_score = word_data[1:]\n",
    "            query = {\"word\": word}\n",
    "            update_field = {\"category\": category, \"word_score\": word_score}\n",
    "\n",
    "            db_word_score_list.update_one(query, {\"$set\": update_field}, True)       \n",
    "        print \"{0}: Total number of words: {1}\".format(category, len(word_tf_idf))\n",
    "    \n",
    "    client.close()\n",
    "\n",
    "\n",
    "def get_category_data_from_db(category_id, request_field_list):\n",
    "    client, db = connect_to_db()\n",
    "    db_category_data = db.category_data\n",
    "    result = []\n",
    "    if not isinstance(request_field_list, list):\n",
    "        request_field_list = [request_field_list]\n",
    "        isOnefield = True\n",
    "    query = list(db_category_data.find({\"category_id\": category_id}))\n",
    "    if len(query) > 0:\n",
    "        query = query[0]\n",
    "        for request_field in request_field_list:        \n",
    "            if request_field in query:\n",
    "                result.append(query[request_field])\n",
    "            else:\n",
    "                print \"{0} not in category {1}\".format(request_field, category_id)\n",
    "                result.append([])\n",
    "    else:\n",
    "        print \"category {0} not in db\".format(category_id)\n",
    "        result = [[] for request_field in request_field_list]\n",
    "    if isOnefield == True:\n",
    "        result = result[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordlist generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_similarity(word1, word2):\n",
    "    \"\"\"Find the similarity between two words, which equals the dot product of their vectors\"\"\"\n",
    "    similarity = 0\n",
    "    word1=word1.lower()\n",
    "    word2=word2.lower()\n",
    "    if word1 in model and word2 in model:\n",
    "        word1_vec = model[word1]\n",
    "        word2_vec = model[word2]\n",
    "        similarity = np.dot(word1_vec, word2_vec)\n",
    "    return similarity\n",
    "\n",
    "def get_wordlist_from_aspect_candidates(seed_word, word_tf_idf, similarity_threshold, score_threshold):\n",
    "    \"\"\"Method 1: directly find the word list from all words whose similarity with the seed_word and tf-idf score are above \n",
    "    certain threshold\"\"\"\n",
    "    word_list = []\n",
    "    for word_data in word_tf_idf:\n",
    "        word = word_data[0]\n",
    "        tf_idf = word_data[1]\n",
    "        if tf_idf > score_threshold:\n",
    "            similarity = get_similarity(seed_word, word)\n",
    "            if similarity > similarity_threshold:\n",
    "                word_list.append([word, similarity, tf_idf])              \n",
    "    word_list_sorted = sorted(word_list, key=lambda tup: tup[1], reverse=True)\n",
    "    return word_list_sorted\n",
    "\n",
    "\n",
    "def get_wordlist_by_tf_idf(seed_word_list, category_id):\n",
    "    \"\"\"Method 2: Find the word_list who can distinguish the chosen sentences from other sentences\"\"\"\n",
    "    \n",
    "    # For each seed_word in seed_word_list, get the word_data for all sentences. word_data has 4 fields [num_word_total, num_doc_total, \n",
    "    # num_word_in_topic, num_doc_in_topic, similarity with seed_word], the first two are from all sentences, and the latter two are from the sentences \n",
    "    # that contain the seed_word.   \n",
    "    client, db = connect_to_db()\n",
    "    db_category_data = db.category_data\n",
    "    db_product_collection = db.product_collection\n",
    "    db_category_collection = db.category_collection\n",
    "    \n",
    "    category_content = list(db_category_data.find({\"category_id\": category_id}))[0]\n",
    "    num_seed_word = len(seed_word_list)\n",
    "    category = category_content[\"category\"]\n",
    "    word_statistics_dic_list = [{} for i in range(num_seed_word)]\n",
    "    \n",
    "    num_sentence_topic_list = [0 for k in range(num_seed_word)]\n",
    "    num_sentence_total_list = [0 for k in range(num_seed_word)]\n",
    "    i = 0\n",
    "    print \"{0}\".format(category)\n",
    "    print \"Number of sentences processed:\"\n",
    "    \n",
    "    prod_id_list = category_content[\"prod_id_list\"]\n",
    "    prod_num = len(prod_id_list)\n",
    "        \n",
    "    for product_id in prod_id_list:          \n",
    "        query_res = list(db_product_collection.find({\"product_id\": product_id}))\n",
    "        contents = query_res[0][\"contents\"]\n",
    "        for sentence in contents:\n",
    "            i += 1\n",
    "            if i % 50000 == 0:\n",
    "                print i\n",
    "            tokens = tokenize(sentence, stem = False)\n",
    "            tokens_count = Counter(tokens)\n",
    "            for word in tokens_count:\n",
    "                # check for each seed_word:\n",
    "                for k in range(num_seed_word):\n",
    "                    seed_word = seed_word_list[k]\n",
    "                    if seed_word in sentence: \n",
    "                        num_sentence_topic_list[k] += 1\n",
    "                        num_sentence_total_list[k] += 1\n",
    "                        if word not in word_statistics_dic_list[k]:\n",
    "                            word_statistics_dic_list[k][word] = [tokens_count[word], 1, tokens_count[word], 1]\n",
    "                        else:\n",
    "                            word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                            word_statistics_dic_list[k][word][1] += 1\n",
    "                            word_statistics_dic_list[k][word][2] += tokens_count[word]\n",
    "                            word_statistics_dic_list[k][word][3] += 1\n",
    "                    else:\n",
    "                        num_sentence_total_list[k] += 1\n",
    "                        if word not in word_statistics_dic_list[k]:\n",
    "                            word_statistics_dic_list[k][word] = [tokens_count[word], 1, 0, 0]\n",
    "                        else:\n",
    "                            word_statistics_dic_list[k][word][0] += tokens_count[word]\n",
    "                            word_statistics_dic_list[k][word][1] += 1\n",
    "\n",
    "    # Get the maximum word frequency for each seed_word group:\n",
    "    word_tf_idf_ratio_list = [[] for k in range(num_seed_word)]\n",
    "    max_num_word_total_list =[0 for k in range(num_seed_word)]\n",
    "    max_num_word_topic_list =[0 for k in range(num_seed_word)] \n",
    "    for k in range(num_seed_word):    \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            if word_data[0] > max_num_word_total_list[k]:\n",
    "                max_num_word_total_list[k] = word_data[0]\n",
    "            if word_data[2] > max_num_word_topic_list[k]:\n",
    "                max_num_word_topic_list[k] = word_data[2]\n",
    "    \n",
    "    # Get tf_idf adjusted ratio for each word, to measure how this word can distinguish the topic sentences:\n",
    "    for k in range(num_seed_word):        \n",
    "        for word in word_statistics_dic_list[k]:\n",
    "            word_data = word_statistics_dic_list[k][word]\n",
    "            num_word_total = word_data[0]\n",
    "            num_word_topic = word_data[2]\n",
    "            num_doc_total = word_data[1]   \n",
    "            num_doc_topic = word_data[3]\n",
    "        \n",
    "            if num_doc_topic == 0 or num_doc_total == 0:\n",
    "                word_tf_idf_ratio_list[k].append([word, 0, 0, 0])\n",
    "                continue\n",
    "\n",
    "            tf_topic = float(num_word_topic) / max_num_word_topic_list[k]\n",
    "            tf_total = float(num_word_total) / max_num_word_total_list[k]\n",
    "            tf_ratio = (tf_topic/num_word_topic) / (tf_total/num_doc_total)\n",
    "\n",
    "            idf_topic = math.log(float(num_sentence_topic_list[k]) / num_doc_topic)\n",
    "            idf_total = math.log(float(num_sentence_total_list[k]) / num_doc_total) \n",
    "\n",
    "            word_tf_idf_ratio_list[k].append([word, 0, 0, tf_topic * math.log(tf_ratio) * idf_total ** 2, tf_topic, tf_total, tf_ratio, idf_topic, idf_total])\n",
    "\n",
    "        word_tf_idf_ratio_list[k].sort(key=lambda tup: tup[3], reverse=True)\n",
    " \n",
    "    word_tf_idf_ratio_list = [item[:300] for item in word_tf_idf_ratio_list]\n",
    "    query = {\"category_id\": category_id}\n",
    "    update_field = {\"word_tf_idf_ratio_list\": word_tf_idf_ratio_list,\"seed_word_list\": seed_word_list}\n",
    "    db.category_data.update_one(query, {\"$set\": update_field}, True)\n",
    "    \n",
    "    client.close()\n",
    "    return word_tf_idf_ratio_list\n",
    "\n",
    "\n",
    "def generate_wordlist_dict(seed_word_list, word_tf_idf_ratio_list, num_words_in_list, sim_slope = 1, sim_intercept = 0.2, isPrint = True):\n",
    "    num_seed_word = len(seed_word_list)\n",
    "    for k in range(num_seed_word): \n",
    "        length = len(word_tf_idf_ratio_list[k])\n",
    "        for j in range(min(range(200),length)):\n",
    "            word_data = word_tf_idf_ratio_list[k][j]\n",
    "            word = word_data[0]\n",
    "            similarity = get_similarity(word, seed_word_list[k])\n",
    "            sim_amplify = sim_intercept + similarity * sim_slope\n",
    "            word_tf_idf_ratio_list[k][j][2] = sim_amplify\n",
    "            argument = 1 + word_tf_idf_ratio_list[k][j][3] * sim_amplify\n",
    "            if argument > 0:\n",
    "                word_tf_idf_ratio_list[k][j][1] = math.log(argument) \n",
    "            else:\n",
    "                word_tf_idf_ratio_list[k][j][1] = -1\n",
    "        word_tf_idf_ratio_list[k].sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    word_tf_idf_ratio_list = [item[:num_words_in_list] for item in word_tf_idf_ratio_list]\n",
    "    wordlist_dict = {}\n",
    "    for k in range(num_seed_word):\n",
    "        wordlist_dict[seed_word_list[k]] = [[word_data[0],word_data[1]] for word_data in word_tf_idf_ratio_list[k][:num_words_in_list]] \n",
    "    \n",
    "    if isPrint == True:\n",
    "        for aspect in wordlist_dict:\n",
    "            print '\"{0}\": '.format(aspect)\n",
    "            print '  ',\n",
    "            for word_data in wordlist_dict[aspect]:\n",
    "                print '\"%s\", %0.2f;'%(word_data[0], word_data[1]),\n",
    "            print\n",
    "    \n",
    "    return wordlist_dict\n",
    "\n",
    "def prune_wordlist_dict(wordlist_dict, excluded_word_external = [], preserve_top = False, isPrint = True):\n",
    "    word_location = {}\n",
    "    excluded_wordlist = [\"good\", \"great\", \"well\", \"bad\", \"worse\",\"better\", \"camera\"] + excluded_word_external\n",
    "    # Obtaining each word's aspects and score in that aspect:   \n",
    "    if preserve_top == True:\n",
    "        for aspect in wordlist_dict:\n",
    "            for word_data in wordlist_dict[aspect]:\n",
    "                word = word_data[0]\n",
    "                score = word_data[1]\n",
    "                if word in word_location:\n",
    "                    word_location[word].append([aspect, score])\n",
    "                else:\n",
    "                    word_location[word]=[[aspect, score]]             \n",
    "\n",
    "        # Sort each word's aspect, and only keep the word in highest score aspect:   \n",
    "        wordlist_dict_pruned = {}\n",
    "        for word in word_location:\n",
    "            if word in excluded_wordlist:\n",
    "                continue\n",
    "            aspect_sorted = sort_list(word_location[word], 1)\n",
    "            aspect_chosen = aspect_sorted[0] # Choose the first one\n",
    "            aspect = aspect_chosen[0]\n",
    "            if aspect in wordlist_dict_pruned:\n",
    "                wordlist_dict_pruned[aspect].append([word, aspect_chosen[1]])\n",
    "            else:\n",
    "                wordlist_dict_pruned[aspect] = [[word, aspect_chosen[1]]]\n",
    "    else:\n",
    "        wordlist_dict_pruned = {}\n",
    "        for aspect in wordlist_dict:\n",
    "            wordlist = []\n",
    "            for word in wordlist_dict[aspect]:\n",
    "                if word[0] not in excluded_wordlist:\n",
    "                    wordlist.append(word) \n",
    "            wordlist_dict_pruned[aspect] = wordlist\n",
    "    \n",
    "    # Sort each word\n",
    "    for word in wordlist_dict_pruned:\n",
    "        wordlist = wordlist_dict_pruned[word]\n",
    "        wordlist_dict_pruned[word] = sort_list(wordlist, 1)\n",
    "    \n",
    "    if isPrint == True:\n",
    "        for aspect in wordlist_dict_pruned:\n",
    "            print '\"{0}\": '.format(aspect)\n",
    "            print '  ',\n",
    "            for word_data in wordlist_dict_pruned[aspect]:\n",
    "                print '\"%s\", %0.2f;'%(word_data[0], word_data[1]),\n",
    "            print\n",
    "        \n",
    "    return wordlist_dict_pruned\n",
    "\n",
    "def iterate_wordlist_dict(wordlist_dict,sentence_list, num_words_in_list, sim_slope = 0.5, sim_intercept = 0.2):\n",
    "    num_aspect = len(wordlist_dict)\n",
    "    word_statistics_dic_list = [{} for i in range(num_aspect)]\n",
    "    num_sentence_topic_list = [0 for k in range(num_aspect)]\n",
    "    num_sentence_total_list = [0 for k in range(num_aspect)]\n",
    "    \n",
    "    i = 0\n",
    "    for sentence in sentence_list: \n",
    "        i += 1\n",
    "        if i % 50000 == 0:\n",
    "            print i\n",
    "        tokens = tokenize(sentence, stem = False)\n",
    "        tokens_count = Counter(tokens)\n",
    "\n",
    "\n",
    "def writeWordlistDictToDB(category_id, wordlist_dict):\n",
    "    # Update database:    \n",
    "    client, db = connect_to_db()\n",
    "    query = {\"category_id\": category_id}\n",
    "    update_field = {\"wordlist_dict\": wordlist_dict}\n",
    "    db.category_data.update_one(query, {\"$set\": update_field}, True)\n",
    "    category = list(db.category_data.find({\"category_id\": category_id}))[0][\"category\"]\n",
    "    \n",
    "    query_category = {\"category_id\": category_id}\n",
    "    update_field_category = {\"category\": category, \"wordlist_dict\": wordlist_dict}\n",
    "    db.category_collection.update_one(query_category, {\"$set\": update_field_category}, True)\n",
    "    client.close()\n",
    "\n",
    "\n",
    "def getWordlistDictFromDB(category):\n",
    "    client, db = connect_to_db()\n",
    "    category_collection = db.category_collection\n",
    "    query_res = list(category_collection.find({\"category\": category}))\n",
    "    disconnect_db(client)\n",
    "\n",
    "    if len(query_res) < 1:\n",
    "        raise Exception('Category: {0} not found in database'.format(category))\n",
    "    elif len(query_res) > 1:\n",
    "        raise Exception('Category: {0} found multiple occurances in database'.format(category))\n",
    "\n",
    "    result = query_res[0]\n",
    "    wordlistDictWithWeights = result['wordlist_dict']\n",
    "    wordlistDict = {}\n",
    "    for aspect in wordlistDictWithWeights:\n",
    "        wordlistDict[aspect] = [sublist[0] for sublist in wordlistDictWithWeights[aspect]]\n",
    "\n",
    "    return wordlistDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pictures\": \n",
      "   \"pictures\", 3.54; \"camera\", 1.28; \"takes\", 1.05; \"great\", 1.00; \"good\", 0.94; \"take\", 0.93; \"quality\", 0.90; \"flash\", 0.84; \"picture\", 0.80; \"videos\", 0.75;\n",
      "\"price\": \n",
      "   \"price\", 4.55; \"prices\", 2.11; \"quality\", 1.95; \"priced\", 1.92; \"good\", 1.87; \"range\", 1.86; \"camera\", 1.85; \"better\", 1.56; \"reasonable\", 1.53; \"worth\", 1.51;\n",
      "\"zoom\": \n",
      "   \"zoom\", 4.30; \"optical\", 2.43; \"x\", 2.34; \"zooming\", 2.01; \"camera\", 1.92; \"lens\", 1.91; \"video\", 1.80; \"zoomed\", 1.70; \"digital\", 1.69; \"mm\", 1.52;\n",
      "\"ease of use\": \n",
      "   \"easy\", 2.68; \"use\", 1.89; \"camera\", 1.04; \"pictures\", 1.00; \"great\", 0.98; \"takes\", 0.88; \"good\", 0.72; \"carry\", 0.70; \"operate\", 0.68; \"small\", 0.68;\n",
      "\"detection\": \n",
      "   \"detection\", 6.34; \"face\", 4.12; \"phase\", 3.44; \"blink\", 3.31; \"smile\", 3.29; \"mode\", 3.20; \"stabilization\", 2.98; \"focus\", 2.79; \"optical\", 2.72; \"auto\", 2.71;\n",
      "\"batteries\": \n",
      "   \"battery\", 4.20; \"batteries\", 2.25; \"charge\", 1.86; \"extra\", 1.81; \"camera\", 1.75; \"charger\", 1.74; \"rechargeable\", 1.62; \"compartment\", 1.39; \"lithium\", 1.30; \"use\", 1.29;\n",
      "\"design\": \n",
      "   \"design\", 5.79; \"designed\", 4.74; \"camera\", 3.02; \"designs\", 2.89; \"flaw\", 2.89; \"designers\", 2.55; \"lens\", 2.50; \"quality\", 2.48; \"designer\", 2.44; \"compact\", 2.44;\n",
      "\"video\": \n",
      "   \"video\", 4.43; \"videos\", 3.20; \"hd\", 2.62; \"recording\", 2.26; \"camera\", 2.19; \"quality\", 2.04; \"zoom\", 1.91; \"sound\", 1.85; \"pictures\", 1.76; \"mode\", 1.76;\n",
      "\"quality\": \n",
      "   \"quality\", 3.98; \"picture\", 1.92; \"good\", 1.91; \"excellent\", 1.53; \"video\", 1.51; \"camera\", 1.49; \"high\", 1.49; \"better\", 1.42; \"image\", 1.36; \"price\", 1.26;\n",
      "\"screen\": \n",
      "   \"screen\", 4.73; \"lcd\", 3.07; \"touch\", 2.64; \"camera\", 2.27; \"touchscreen\", 1.93; \"viewing\", 1.89; \"bright\", 1.87; \"screens\", 1.85; \"picture\", 1.85; \"display\", 1.73;\n",
      "\"size\": \n",
      "   \"size\", 4.93; \"small\", 2.61; \"sized\", 2.49; \"weight\", 2.43; \"sizes\", 2.18; \"quality\", 2.12; \"compact\", 1.99; \"smaller\", 1.92; \"pocket\", 1.91; \"larger\", 1.84;\n"
     ]
    }
   ],
   "source": [
    "category_id = 308 # Camera\n",
    "seed_word_list = [\"batteries\", \"pictures\",\"price\",\"zoom\",\"ease of use\", \"detection\",\"design\",\"video\",\"quality\",\"screen\",\"size\"]\n",
    "sim_slope = 1\n",
    "sim_intercept = 0.2\n",
    "\n",
    "# word_tf_idf_ratio_list = get_wordlist_by_tf_idf(seed_word_list, category_id)\n",
    "wordlist_dict = generate_wordlist_dict(seed_word_list, word_tf_idf_ratio_list, 10, sim_slope, sim_intercept)\n",
    "wordlist_dict_pruned = prune_wordlist_dict(wordlist_dict)\n",
    "writeWordlistDictToDB(category_id, wordlist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pictures\": \n",
      "   \"pictures\", 3.54; \"takes\", 1.05; \"take\", 0.93; \"quality\", 0.90; \"flash\", 0.84; \"picture\", 0.80; \"videos\", 0.75;\n",
      "\"price\": \n",
      "   \"price\", 4.55; \"prices\", 2.11; \"quality\", 1.95; \"priced\", 1.92; \"range\", 1.86; \"reasonable\", 1.53; \"worth\", 1.51;\n",
      "\"zoom\": \n",
      "   \"zoom\", 4.30; \"optical\", 2.43; \"x\", 2.34; \"zooming\", 2.01; \"lens\", 1.91; \"video\", 1.80; \"zoomed\", 1.70; \"digital\", 1.69; \"mm\", 1.52;\n",
      "\"ease of use\": \n",
      "   \"easy\", 2.68; \"use\", 1.89; \"pictures\", 1.00; \"takes\", 0.88; \"carry\", 0.70; \"operate\", 0.68; \"small\", 0.68;\n",
      "\"detection\": \n",
      "   \"detection\", 6.34; \"face\", 4.12; \"phase\", 3.44; \"blink\", 3.31; \"smile\", 3.29; \"mode\", 3.20; \"stabilization\", 2.98; \"focus\", 2.79; \"optical\", 2.72; \"auto\", 2.71;\n",
      "\"batteries\": \n",
      "   \"battery\", 4.20; \"batteries\", 2.25; \"charge\", 1.86; \"extra\", 1.81; \"charger\", 1.74; \"rechargeable\", 1.62; \"compartment\", 1.39; \"lithium\", 1.30; \"use\", 1.29;\n",
      "\"design\": \n",
      "   \"design\", 5.79; \"designed\", 4.74; \"designs\", 2.89; \"flaw\", 2.89; \"designers\", 2.55; \"lens\", 2.50; \"quality\", 2.48; \"designer\", 2.44; \"compact\", 2.44;\n",
      "\"video\": \n",
      "   \"video\", 4.43; \"videos\", 3.20; \"hd\", 2.62; \"recording\", 2.26; \"quality\", 2.04; \"zoom\", 1.91; \"sound\", 1.85; \"pictures\", 1.76; \"mode\", 1.76;\n",
      "\"quality\": \n",
      "   \"quality\", 3.98; \"picture\", 1.92; \"excellent\", 1.53; \"video\", 1.51; \"high\", 1.49; \"image\", 1.36; \"price\", 1.26;\n",
      "\"screen\": \n",
      "   \"screen\", 4.73; \"lcd\", 3.07; \"touch\", 2.64; \"touchscreen\", 1.93; \"viewing\", 1.89; \"bright\", 1.87; \"screens\", 1.85; \"picture\", 1.85; \"display\", 1.73;\n",
      "\"size\": \n",
      "   \"size\", 4.93; \"small\", 2.61; \"sized\", 2.49; \"weight\", 2.43; \"sizes\", 2.18; \"quality\", 2.12; \"compact\", 1.99; \"smaller\", 1.92; \"pocket\", 1.91; \"larger\", 1.84;\n"
     ]
    }
   ],
   "source": [
    "wordlist_dict_pruned = prune_wordlist_dict(wordlist_dict)\n",
    "writeWordlistDictToDB(308,wordlist_dict_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73, 433, 399, 153, 297, 136, 22, 456, 322, 450, 80, 340]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = (u'Electronics', u'Portable Audio & Video', u'Portable DVD Players') #(222, 3977, 22476)\n",
    "category0 = (\"Electronics\", \"Camera & Photo\", \"Digital Cameras\") #(7917, 203926, 1726478)\n",
    "category1 = (u'Cell Phones & Accessories', u'Cell Phones') # (743, 32200, 221681)\n",
    "category2 = (u'Electronics', u'Accessories & Supplies', u'Batteries, Chargers & Accessories') #(7472, 53089, 206542)\n",
    "category3 = (u'Electronics', u'Computers & Accessories', u'Monitors') #(3731, 51922, 364001)\n",
    "category4 = (u'Electronics', u'Camera & Photo', u'Lenses') #(3737, 61874, 453186)\n",
    "category5 = (u'Electronics', u'Computers & Accessories', u'Tablets') #(2439, 99311, 781032)\n",
    "category6 = (u'Electronics', u'Television & Video', u'Televisions') #(4227, 141665, 1291788)\n",
    "category7 = (u'Cell Phones & Accessories', u'Accessories', u'Headsets')\n",
    "category8 = (u'Electronics', u'Camera & Photo', u'Bags & Cases')\n",
    "category9 = (u'Cell Phones & Accessories', u'Accessories', u'Screen Protectors')\n",
    "category10 = (u'Electronics', u'Portable Audio & Video', u'MP3 Players & Accessories')\n",
    "category11 = (u'Electronics', u'Camera & Photo', u'Accessories')\n",
    "category_list =[category, category1, category2, category3, category4, category5, category6, category7, category8, category9, \\\n",
    "                category10, category11]\n",
    "category_id_list = []\n",
    "for category in category_list:\n",
    "    category_id = category_dict[category]['category_id']\n",
    "    category_id_list.append(category_id)\n",
    "category_id_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
